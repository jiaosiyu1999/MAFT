# python train_net.py --config-file configs/coco-stuff-164k-156/mask2former_maft.yaml --num-gpus 4

_BASE_: ../coco-stuff-164k-171/mask2former_R50_bs32_60k.yaml
MODEL:
  WEIGHTS: out/model.pt   # path/to/freeseg_model
  META_ARCHITECTURE: "MAFT" 
  MASK_FORMER: 
    TEST:
      INSTANCE_ON: False
      PANOPTIC_ON: False
      OVERLAP_THRESHOLD: 0.5
      OBJECT_MASK_THRESHOLD: 0.5
  BACKBONE:
    NAME: "build_resnet_deeplab_backbone"
  SEM_SEG_HEAD:
    NAME: "MaskFormerInteractionHead"
    NUM_CLASSES: 171
    EMBEDDING_DIM: 512
    EMBED_LAYERS: 2
  RESNETS:
    DEPTH: 101
    STEM_TYPE: "deeplab"
    STEM_OUT_CHANNELS: 128
    STRIDE_IN_1X1: False
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    # NORM: "SyncBN"
    RES5_MULTI_GRID: [1, 2, 4]
  START_LAYERS: 8
  CLIP_ADAPTER:
    PROMPT_LEARNER: "predefined"
    PROMPT_DIM: 512
    PROMPT_SHAPE: (16, 0)
    CLIP_MODEL_NAME: "ViT-B/16"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    SEPERATE_ADAPTER: False
    CLIP_ENSEMBLE: True
    CLIP_ENSEMBLE_WEIGHT: 0.0

INPUT:
  IMAGE_SIZE: 640  
  DATASET_MAPPER_NAME: "mask_former_semantic" 
DATASETS:
  TRAIN: ("coco_2017_train_stuff_sem_seg",)
  TEST: ('voc_sem_seg_val','pcontext_sem_seg_val','pcontext_full_sem_seg_val','my_ade20k_sem_seg_val','ade20k_full_sem_seg_val')
SOLVER:
  IMS_PER_BATCH: 16
  BASE_LR: 0.00001
  WEIGHT_DECAY: 0.0001
  MAX_ITER: 1000
DATALOADER:
  NUM_WORKERS: 8
TEST:
  EVAL_PERIOD: 1000
OUTPUT_DIR: ./out/MAFT